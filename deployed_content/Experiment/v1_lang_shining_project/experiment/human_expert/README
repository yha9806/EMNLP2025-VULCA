# 中英文绘画评论分析工具 (Chinese & English Painting Critique Analysis Tool) - 分阶段实施指南

## 项目总览

本项目旨在利用自然语言处理（NLP）技术，对中英文绘画评论文本进行深度分析，包括情感倾向、主要特点、评论质量及相似性等。这份README将引导你通过一系列的小项目（阶段性目标）来逐步完成整个工具的开发。

## 如何使用本指南

本指南将整个开发过程分解为若干个独立的"小项目"或"阶段目标"。建议你按顺序完成这些小项目。每个小项目都包含以下部分：

* **🎯 目标 (Goal):** 本阶段要实现的核心功能。
* **🛠️ 涉及模块 (Modules Involved):** 指出这个阶段主要会用到项目的哪些核心分析功能。
* **🚀 主要步骤与代码提示 (Key Steps & Code Hints):** 简述实现该目标的关键步骤和可能用到的代码片段或逻辑。
* **✅ 预期成果 (Expected Outcome):** 完成本阶段后，你应该能看到或得到什么。
* **💡 注意事项 (Notes/Tips):** 一些额外的提示或需要注意的地方。

## 核心技术栈（回顾）

* **Python 3.x**
* **Hugging Face Transformers:** 主要用于通过零样本分类提取文本特征（评价立场、核心关注点、论证质量等），是本阶段（人类学者评论文本基准特征提取）分析的核心工具。它提供了便捷的 `pipeline` API 和丰富的预训练模型。
* **Sentence Transformers:** 计划在项目后续阶段（如AI评论与人类评论对比时）用于计算文本嵌入和语义相似度，以量化不同来源评论在内容上的贴近程度。
* **PyTorch:** 主要的深度学习后端框架，为 Transformers 等库提供支持。
* **Pandas (推荐):** 用于数据组织、元数据管理以及存储和分析本阶段提取的结构化特征数据。

## 通用环境准备 (适用于所有小项目)

1.  **克隆项目/创建项目文件夹:**
    ```bash
    # git clone [your-repository-url] # 如果你已创建git仓库
    # cd [your-project-directory]
    # 或者直接创建项目文件夹
    mkdir painting_critique_analyzer
    cd painting_critique_analyzer
    ```
2.  **创建并激活虚拟环境 (推荐):**
    ```bash
    python -m venv venv
    # Windows: venv\Scripts\activate
    # macOS/Linux: source venv/bin/activate
    ```
3.  **安装基础依赖:**
    创建一个 `requirements.txt` 文件：
    ```txt
    torch
    transformers
    sentence-transformers
    pandas # 推荐
    # openpyxl # 如果要输出到xlsx
    ```
    然后安装：
    ```bash
    pip install -r requirements.txt
    ```
    *注意PyTorch的GPU/CPU版本安装，如有需要请参考PyTorch官网。*

---

## 阶段性目标 (小项目)

### 阶段 0: 环境验证与基础文件读取

* **🎯 目标:** 确保开发环境配置正确，能够成功加载一个本地TXT文件并打印其内容。
* **🛠️ 涉及模块:** Python基础文件操作。
* **🚀 主要步骤与代码提示:**
    1.  创建一个简单的Python脚本 (例如 `test_load_file.py`)。
    2.  实现 `load_critique_from_txt(file_path)` 函数，确保使用 `utf-8` 编码。
        ```python
        def load_critique_from_txt(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return f.read().strip()
            except FileNotFoundError:
                print(f"错误: 文件未找到 {file_path}")
                return None
            except Exception as e:
                print(f"读取文件错误 {file_path}: {e}")
                return None

        # 创建一个测试TXT文件，例如 test_comment.txt，内容为 "这是一条测试评论。"
        # test_content = load_critique_from_txt("test_comment.txt")
        # if test_content:
        # print(f"文件内容: {test_content}")
        ```
    3.  准备一个简单的TXT文件（例如 `comment_example.txt`，包含一两句中英文评论），并尝试加载。
* **✅ 预期成果:** 脚本能够无误地打印出 `comment_example.txt` 文件中的文本内容。
* **💡 注意事项:** 路径问题，文件编码问题。

### 阶段 1: 人类学者评论文本基准特征提取

* **🎯 目标 (Goal):** 对已收集的人类学者中国画评论文本进行深度、多维度分析，提取其评价立场光谱、核心评论关注点以及论证质量相关的特征。这些特征将作为后续构建基准模型的基础数据。
* **🛠️ 涉及模块 (Modules Involved):** Hugging Face Transformers (主要使用 `zero-shot-classification` 模型), Python 文件操作 (复用阶段0的功能), Pandas (用于组织和存储提取的特征数据)。
* **🛠️ 涉及脚本 (Scripts Involved):**
    *   `experiment/human_expert/src/phase1/extract_human_expert_features.py`: 负责执行实际的特征提取流程。
* **🚀 主要步骤与代码提示 (Key Steps & Code Hints):**
    *   **通用准备:**
        1.  确保阶段0的 `load_critique_from_txt(file_path)` 函数可用。
        2.  从 `transformers` 导入 `pipeline`: `from transformers import pipeline`。
        3.  加载零样本分类模型：`analyzer = pipeline("zero-shot-classification", model="MoritzLaurer/mDeBERTa-v3-base-mnli-xnli")` (或其他选定的多语言零样本模型，确保其支持中文)。
        4.  初始化一个列表，用于存储所有评论的分析结果: `all_critique_features = []`。
        5.  (可选) 如果需要处理大量文件，可以使用 `os.walk` 或 `glob` 来遍历您的数据集目录。

    *   **1. 提取评价立场光谱 (Evaluative Stance Spectrum):**
        *   定义候选评价立场标签：
            ```python
            stance_labels = [
                "历史考证型", "美学鉴赏型", "社会文化解读型", 
                "比较分析型", "理论建构型", "质疑与思辨型",
                "高度赞扬与推崇", "客观中性描述", "温和批评与保留", "强烈否定与驳斥"
            ] # 可根据实际需要调整和扩展
            ```
        *   对于每条评论文本 (`critique_text`)：
            `stance_results = analyzer(critique_text, candidate_labels=stance_labels, multi_label=False)` # 或 multi_label=True，根据需求选择
            `# 记录立场结果，例如: extracted_stance = {"label": stance_results['labels'][0], "score": stance_results['scores'][0]}`

    *   **2. 提取核心评论关注点 (Core Focal Points):**
        *   定义候选核心关注点标签：
            ```python
            feature_labels = [
                "色彩运用", "笔法技巧", "皴法特点", "线条质量", "墨法变化", 
                "构图布局", "空间营造", "画面结构", "意境表达", "情感传递", 
                "主题内容", "题材选择", "象征意义", "历史背景", "画家生平", 
                "风格流派", "技法传承与创新", "跨文化影响"
            ] # 可根据实际需要调整和扩展
            ```
        *   对于同一条评论文本 (`critique_text`)：
            `feature_results = analyzer(critique_text, candidate_labels=feature_labels, multi_label=True)`
            `# 记录关注点结果，例如: extracted_features = dict(zip(feature_results['labels'], feature_results['scores']))`

    *   **3. 提取论证质量特征 (Argumentative Quality Features):**
        *   定义候选论证质量标签：
            ```python
            quality_labels = [
                "见解深刻独到", "论证充分有力", "逻辑清晰严密", "细节分析具体",
                "引用经典佐证", "观点客观公允", "论述流于表面", "内容较为宽泛",
                "缺乏具体例证", "逻辑存在跳跃", "观点主观片面"
            ] # 可根据实际需要调整和扩展
            ```
        *   对于同一条评论文本 (`critique_text`)：
            `quality_results = analyzer(critique_text, candidate_labels=quality_labels, multi_label=True)`
            `# 记录论证质量结果，例如: extracted_quality = dict(zip(quality_results['labels'], quality_results['scores']))`

    *   **数据汇总与存储 (对每条评论):**
        *   假设 `file_identifier` 是当前评论的文件名或唯一ID。
        *   `current_critique_data = {"id": file_identifier, "text": critique_text, "stance": extracted_stance, "features": extracted_features, "quality": extracted_quality}`
        *   `all_critique_features.append(current_critique_data)`
    
    *   **最终保存 (处理完所有评论后):**
        *   (推荐) 使用Pandas将 `all_critique_features` 列表转换为DataFrame，并保存为CSV文件。
            ```python
            # import pandas as pd
            # df_features = pd.DataFrame(all_critique_features)
            # df_features.to_csv("human_expert_features.csv", index=False, encoding='utf-8-sig')
            # print("所有人类学者评论特征已提取并保存到 human_expert_features.csv")
            ```

* **✅ 预期成果 (Expected Outcome):**
    1.  为数据集中每一份人类学者评论文本，都生成一个包含其评价立场、核心关注点、论证质量特征的多维度结构化描述（标签及对应分数）。
    2.  所有文本的特征提取结果被汇总并存储在一个易于分析的主CSV文件（如 `experiment/human_expert/result/human_expert_features_consolidated.csv`）以及可能的按学者/作品分类的CSV文件（位于 `experiment/human_expert/result/per_scholar_results/` 目录）中，为后续阶段的基准建模工作提供直接的数据输入。
    3.  **此脚本不直接生成图片文件。**

* **💡 注意事项 (Notes/Tips):**
    1.  **标签迭代优化：** 上述提供的候选标签仅为示例，强烈建议根据您的具体研究视角和对人类学者评论文本的初步观察，仔细设计和迭代优化这三组标签，使其更贴合中国画评论的领域特性。
    2. **模型选择：** 您可以考虑以下模型作为备选。请注意，这些模型在类型和适用任务上可能与原先主要用于零样本分类的NLI模型 (`MoritzLaurer/mDeBERTa-v3-base-mnli-xnli`) 有所不同（例如，您列出的新模型中包含视觉语言模型(VLM)和通用大语言模型(LLM)）。因此，它们具体的使用方式（例如，是否能直接套用Hugging Face的 `zero-shot-classification` pipeline，或者是否需要采用自定义的提示工程、API调用或其他特定于模型的集成方法）需要根据各个模型的特性进行仔细评估和调整。
    *   `Qwen/Qwen2.5-VL-7B-Instruct`
    *   `Qwen/Qwen2.5-Omni-7B`
    *   `deepseek-ai/Janus-Pro-7B`
    *   `deepseek-ai/deepseek-vl2`
    *   `meta-llama/Llama-4-Scout-17B-16E-Instruct`
    *   `Qwen/Qwen3-235B-A22B`
    *   `google/gemma-3-27b-it`
    在选择和使用这些模型时，请确保它们对中文文本的处理效果良好，并注意首次运行时可能需要下载模型文件（部分模型可能非常大），且通常需要稳定的网络连接。
    3.  **批量处理：** 实际操作中，您会遍历您已收集的所有人类学者文本文件，对每个文件内容执行上述特征提取流程。建议先用少量样本测试完整流程，再进行大规模处理。
    4.  **结果解释与使用：** 零样本分类的分数代表模型认为标签与文本的匹配程度。如何解读和使用这些分数（例如，是取最高分标签，还是关注多个高分标签组合，或是设定阈值筛选）需要根据后续"基准建模"的具体分析目标来确定。
    5.  此阶段的核心是高效、准确地完成特征提取。后续的"基准建模"阶段将基于这些提取出的特征进行统计分析、模式发现、聚合打分等更复杂的操作，以最终形成可供对比的"黄金标准"。
    6.  考虑到处理时间和API限制（如果有的话），对于非常长的评论文本，可能需要考虑分段处理或摘要后处理的策略，但这会增加复杂性，需谨慎评估。

### 阶段 2: 基准定义与初步分析 (Benchmark Definition and Initial Analysis)

* **🎯 目标 (Goal):**
    *   基于"阶段 1"提取的人类学者中国画评论特征数据 (存储于 `human_expert_features_consolidated.csv`，此文件名来自原始文档，实际输出文件名应与 `extract_human_expert_features.py` 一致)，进行初步的数据探索和分析。
    *   开始定义核心的"评论画像"的雏形，并为画像的关键特征进行初步的定性描述和筛选。
* **🛠️ 涉及资源与工具 (Resources & Tools Involved):**
    *   "阶段 1"输出的特征数据 CSV 文件。
    *   数据分析与处理库：Pandas。
    *   （可选）数据可视化库：Matplotlib, Seaborn。
    *   您的中国画艺术史、艺术理论及艺术批评领域的专业知识。
* **🛠️ 涉及脚本 (Scripts Involved):**
    *   `experiment/human_expert/src/phase2/analyze_and_define_benchmarks.py`: 负责加载阶段1的特征数据，进行探索性数据分析(EDA)，并辅助定义评价画像的初步框架和特征。
* **🚀 主要步骤与思路 (Key Steps & Approach):**
    1.  **数据加载与准备：**
        *   使用Pandas加载阶段1生成的特征数据。
        *   如特征或质量数据存储为字典字符串，则进行转换。
    2.  **探索性数据分析 (EDA)：**
        *   分析评价立场、核心关注点、论证质量的整体分布、平均得分等。
        *   （可选）进行特征间的相关性分析。
    3.  **画像初步定义：**
        *   基于EDA结果和专业知识，初步构思几个核心的评论画像（例如："博古通今型"、"尚意唯美型"等）。
        *   为每个画像初步选择和映射最能代表其特质的NLP特征标签（从立场、关注点、论证质量中选取）。
* **✅ 预期成果 (Expected Outcome):**
    *   对阶段1提取的特征数据有初步的统计理解。
    *   完成核心评论画像的初步定性描述和关键特征的初步列表。
    *   为阶段3和阶段4中更具体的画像量化和典范选择奠定基础。
    *   **主要输出文件与可视化（如果绘图代码被执行）：**
        *   **CSV 分析文件 (位于 `experiment/human_expert/result/analysis_results/`)**: `stance_distribution.csv`, `stance_score_stats.csv`, `features_analysis.csv`, `quality_analysis.csv`。
        *   **图片文件 (位于 `experiment/human_expert/result/eda_plots/`)**: 
            *   `stance_distribution.png` (立场标签分布条形图)
            *   `stance_score_distribution.png` (各立场标签的立场得分箱线图)
            *   `core_focal_points_mention_rate.png` (核心关注点提及率条形图)
            *   `core_focal_points_average_score.png` (核心关注点平均得分条形图)
            *   `argumentative_quality_mention_rate.png` (论证质量提及率条形图)
            *   `argumentative_quality_average_score.png` (论证质量平均得分条形图)

* **💡 注意事项 (Notes/Tips):**
    1.  此阶段侧重于从数据中获得洞见，并结合专业知识进行画像的初步概念化。
    2.  输出可能是文档化的画像草案和初步的特征映射表。
    3.  脚本中包含的绘图代码可能部分被注释，需要取消注释以生成所有列出的图片。

### 阶段 3: 基准模型构建 (第一部分 - 画像量化与标准设定) (Benchmark Model Construction Part 1: Profile Quantization & Criteria Setting)

* **🎯 目标 (Goal):**
    *   在阶段2定义的画像基础上，进一步通过数据驱动的方法量化这些画像。
    *   为每个画像的关键特征设定具体的量化标准或期望得分范围/阈值。
    *   整合人类专家与AI（如Gemini）的评论数据，进行对比性的探索分析、特征降维与可视化。
* **🛠️ 涉及资源与工具 (Resources & Tools Involved):**
    *   阶段1输出的特征数据 (`human_expert_features_consolidated.csv`)。
    *   AI模型输出的特征数据 (例如 `mllms_features_consolidated.csv`)。
    *   阶段2定义的画像草案和初步特征列表。
    *   Pandas, Matplotlib, Seaborn, SciPy, Statsmodels, scikit-learn (TSNE), UMAP (optional)。
* **🛠️ 涉及脚本 (Scripts Involved):**
    *   `experiment/human_expert/src/phase3/phase_1_1_benchmark_script_part1.py`: 实现画像的量化逻辑，例如根据统计分布为画像的关键特征设定阈值或得分范围。此脚本也负责整合人类与AI数据，进行EDA、统计比较、降维和可视化。
* **🚀 主要步骤与思路 (Key Steps & Approach):**
    1.  **深化画像特征映射：** 根据阶段2的发现，进一步确认和优化各画像的关键特征。
    2.  **数据驱动的量化：**
        *   分析整体数据中，与各画像相关的关键特征的得分分布。
        *   为每个画像的关键特征设定具体的量化标准（例如，某特征得分应高于X，或在Y到Z之间）。
        *   考虑特征组合在定义画像时的作用。
    3.  **画像标准初稿：** 形成每个画像的量化标准文档初稿。
    4.  **整合与对比分析 (人类 vs AI):** 加载、合并、预处理人类和AI的特征数据，进行立场、特征、质量等方面的统计比较和可视化分析。
* **✅ 预期成果 (Expected Outcome):**
    *   为每个评论画像建立一套初步的、数据驱动的量化评价标准。
    *   生成描述这些量化标准的文档。
    *   对人类专家与AI评论数据在特征层面的异同有初步的量化和可视化理解。
    *   **主要输出文件与可视化：**
        *   **CSV 分析文件 (位于 `experiment/human_expert/result/analysis_results/`)**: 
            *   `eda_summary_statistics_human_gemini.csv` (EDA统计摘要)
            *   `features_dimensionality_reduction_coords_human_gemini.csv` (包含降维坐标的完整数据)
            *   `features_tsne_visualization_human_gemini_data.csv` (t-SNE降维结果)
            *   `features_umap_visualization_human_gemini_data.csv` (UMAP降维结果, 若UMAP可用)
            *   `feature_quality_statistical_comparison.csv` (人类与AI特征的统计对比)
            *   `feature_space_centroids.csv` (基于persona_id的降维空间质心)
        *   **图片文件 (位于 `experiment/human_expert/result/eda_plots/`)**: 
            *   `features_tsne_visualization_human_gemini.png` (t-SNE降维可视化图)
            *   `features_umap_visualization_human_gemini.png` (UMAP降维可视化图, 若UMAP可用)
        *   **日志文件**: `script_debug_output.txt` (位于项目根目录的父级目录)

* **💡 注意事项 (Notes/Tips):**
    1.  这个阶段的目标是将定性的画像描述转化为可操作的、基于数据的规则，并对人类与AI数据进行初步对比。
    2.  可能需要多次迭代调整量化标准。

### 阶段 4: 基准模型构建 (第二部分 - 聚焦性分析与典范选择) (Benchmark Model Construction Part 2: Focus Analysis & Exemplar Selection)

* **🎯 目标 (Goal):**
    *   对评论文本进行聚焦性分析，这可能作为评估论证质量或画像符合度的一个维度。
    *   （可选但推荐）根据阶段3的量化标准以及聚焦性分析结果，从人类学者数据中挑选代表性的"典范评论文本"以验证和优化画像定义。
* **🛠️ 涉及资源与工具 (Resources & Tools Involved):**
    *   阶段1输出的特征数据。
    *   阶段3输出的画像量化标准。
    *   Pandas。
* **🛠️ 涉及脚本 (Scripts Involved):**
    *   `experiment/human_expert/src/phase4/analyze_lacks_focus.py`: 分析评论文本是否缺乏焦点，或是在多个主题间分散。结果可用于细化画像标准或作为一项独立的质量评估指标。
    *   `experiment/human_expert/src/phase4/phase_1_1_benchmark_script_part2_candidate_selection.py`: 根据已建立的画像量化标准和可能的聚焦性分析结果，从数据集中筛选和推荐典范评论文本候选。**此脚本不直接生成图片，但其输出的包含降维坐标的CSV文件（例如 `dimensionality_reduction_with_profile_scores_human_and_gemini.csv`）是后续进行高级可视化（如 `visualize_composite_analysis.py`）的关键数据输入。**
* **🚀 主要步骤与思路 (Key Steps & Approach):**
    1.  **评论聚焦性分析：**
        *   执行 `analyze_lacks_focus.py` 脚本，分析文本的焦点集中程度。
    2.  **典范文本选择（基于脚本 `phase_1_1_benchmark_script_part2_candidate_selection.py`）：**
        *   应用阶段3的量化标准和聚焦性分析结果，自动筛选符合各画像特征的候选典范文本。
        *   人工审核和确认这些候选文本，以确保其真正具有代表性。
    3.  **画像定义迭代：** 根据典范文本的特征表现，回顾和优化画像的定性描述和量化标准。
    4.  **最终画像文档化：** 形成包含定性描述、关键特征、量化标准和典范示例的最终画像模型文档。
* **✅ 预期成果 (Expected Outcome):**
    *   对评论文本聚焦性的分析结果。
    *   一套经过验证和优化的、包含多个核心"中国画评论画像模型"的文档。每个画像模型都具备清晰的定性阐释、具体的量化评价标准，并可能包含典范评论文本示例。
    *   这份结构化的画像模型集合，将作为总项目 `experiment/README.md` "阶段一"任务中"基准模型"的核心产出。
* **💡 注意事项 (Notes/Tips):**
    1.  典范文本的选择对于验证和解释画像模型至关重要。
    2.  `analyze_lacks_focus.py` 的具体实现和输出将决定其如何被有效利用。
    3.  最终的画像模型应该是领域知识和数据分析的结合。
    4.  此阶段的 `visualize_semantic_space.py` 脚本会生成 `unified_semantic_space_plan_b_tsne.png` 图片，展示了t-SNE降维后的画像语义空间，对比人类专家不同画像的语义空间分布（通过凸包和质心）与MLLM生成内容在同一语义空间中的分布（通过散点和整体质心）。

### 阶段 5: 专家评论语义空间构建与可视化 (Semantic Space Construction & Visualization for Expert Critiques)

*   **🎯 目标 (Goal):**
    *   为经过画像分配（或标记）的人类学者评论文本生成高维语义向量。
    *   计算每个已定义画像在语义空间中的平均位置（质心）。
    *   利用 t-SNE 等降维技术对高维语义向量进行降维，并将个体评论文本向量与画像质心向量在二维空间中进行可视化。
    *   通过可视化结果，探索不同画像的文本在语义上的分布、聚集和区分情况。
*   **🛠️ 涉及脚本 (Scripts Involved):**
    *   `experiment/human_expert/src/phase5/generate_semantic_vectors.py`: 负责加载评论文本，使用预训练模型 (如 `BAAI/bge-large-zh-v1.5`) 生成语义向量，计算各画像的质心，并保存这些向量数据。
    *   `experiment/human_expert/src/phase5/visualize_semantic_space.py`: 负责加载生成的个体文本向量和画像质心向量，使用 t-SNE 进行降维，并生成散点图进行可视化。
*   **📄 主要输出文件 (Key Output Files) (基于原始文档，文件名可能需根据脚本实际输出调整):**
    *   包含评论唯一标识、画像标签及对应语义向量的CSV文件 (例如 `human_expert_semantic_vectors_with_profiles.csv`)。
    *   包含画像名称及其平均语义向量 (质心) 的CSV文件 (例如 `profile_semantic_centroids.csv`)。
    *   降维后的二维语义空间可视化图 (例如 `semantic_space_visualization_tsne.png`)。
*   **✅ 预期成果 (Expected Outcome):**
    1.  为每篇人类学者评论文本生成量化的、高维度的语义表示。
    2.  计算出每个预定义画像在语义空间中的代表性位置（质心）。
    3.  获得一个直观的可视化图表，展示不同画像下的评论文本在语义层面上的分布模式和区分度。
    4.  为后续AI评论与人类专家评论进行语义相似度比较和画像一致性评估奠定基础。
*   **💡 注意事项 (Notes/Tips):**
    1.  语义向量的质量高度依赖于所选的预训练模型。
    2.  t-SNE 降维结果的可解释性依赖于参数选择，主要用于可视化探索。
    3.  可视化图谱中画像的聚集和分离情况可为画像定义的合理性提供旁证。

### 阶段 6: 更多可视化分析与成果汇总 (Advanced Visualizations & Results Consolidation)

*   **🎯 目标 (Goal):**
    *   对各类分析结果进行更丰富的可视化展示，全面对比和理解人类专家评论与AI生成评论的特性。
    *   汇总所有关键的可视化成果。
*   **🛠️ 涉及脚本 (Scripts Involved) 与主要可视化输出:**
    *   **1. 作者语义空间可视化 (`experiment/human_expert/src/phase5/visualize_author_semantic_space.py`):**
        *   **生成图片:** `combined_author_semantic_space_visualization_tsne.png`
        *   **内容:** t-SNE降维后的作者语义空间可视化。图中显示了不同作者（区分人类专家和MLLM）的各个文本段落在语义空间中的分布，以及各自作者的质心。
        *   **保存路径:** `experiment/human_expert/result/eda_plots/combined_author_semantic_space_visualization_tsne.png`
    *   **2. 聚合基准特性分析 (`experiment/human_expert/src/analyze_aggregated_benchmark_properties.py`):**
        *   **生成多张图片，例如:**
            *   学者/书籍立场分布条形图 (如 `scholar_stance_distribution.png`)
            *   学者/书籍示例特征直方图 (如 `scholar_feature_distribution.png`)
            *   学者/书籍语义质心t-SNE可视化图 (如 `scholar_semantic_space_tsne.png`)
            *   学者/书籍语义质心UMAP可视化图 (如 `scholar_semantic_space_umap.png`)
        *   **内容:** 这些图片分别展示了在学者层面和书籍层面聚合后的特征（如立场、特定特征得分）的分布情况，以及聚合后的语义质心在降维空间（t-SNE, UMAP）中的分布。
        *   **保存路径:** `experiment/human_expert/result/analysis_results/aggregated_benchmark_analysis/` 及其子目录 (`scholar_feature_distributions`, `book_feature_distributions`)。
    *   **3. 复合对比可视化 (`experiment/human_expert/src/visualize_composite_analysis.py`):**
        *   **生成图片1:** `composite_analysis_hulls.png`
            *   **内容:** 复合图，包含：人类专家与MLLM各类画像在t-SNE/UMAP空间的凸包(Hulls)分布图，以及针对某一例文本的人类专家与MLLM的画像比例堆叠柱状图和点图。
            *   **保存路径:** `experiment/human_expert/result/eda_plots/composite_analysis_hulls.png`
        *   **生成图片2:** `composite_analysis_kde_radar.png`
            *   **内容:** 复合图，包含：人类专家与MLLM各类画像在t-SNE空间的核密度估计(KDE)分布图，以及针对某一例文本的人类专家与MLLM的画像比例雷达图。
            *   **保存路径:** `experiment/human_expert/result/eda_plots/composite_analysis_kde_radar.png`
*   **✅ 预期成果 (Expected Outcome):**
    1.  一系列直观、信息丰富的可视化图表，清晰展示不同维度下的分析结果。
    2.  对人类评论与AI评论在语义、特征、画像等方面的异同有更深入的理解。
*   **💡 注意事项 (Notes/Tips):**
    1.  确保所有可视化脚本都能正确读取其依赖的CSV数据文件。
    2.  注意图片的可读性，如图例、标签、标题的清晰度。
    3.  这些可视化是项目成果展示和论文撰写的重要素材。

---
