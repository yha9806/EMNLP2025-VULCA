DeepSeek-GRM: Inferene-time Scalingçš„é€šç”¨å¥–åŠ±æ¨¡åž‹ï¼ˆGRMï¼‰
 



1. ç»“è®º(take away)
Training Scaling å’Œ Inference Scaling åœ¨ Base-Model éƒ½å–å¾—äº†å·¨å¤§çš„æˆåŠŸã€‚é‚£ä¹ˆåœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰è¿‡ç¨‹ä¸­éœ€è¦çš„ Reward-Modelï¼ˆRMï¼‰ æ˜¯ä¸æ˜¯ä¹Ÿå¯ä»¥é€šè¿‡ Inference-Time Scaling æ¥ä¼˜åŒ– RM å‘¢ï¼Ÿå› æ­¤ DeepSeek å›¢é˜Ÿæå‡ºä¸€ç§æ–¹æ³•å«åšï¼šSelf-Principed Critique Tuning (SPCT) çš„æ–¹æ³•æ¥è®­ç»ƒä¸€ä¸ªé€šç”¨åž‹çš„ RMï¼ˆGeneralist RMï¼‰ã€‚

RL åœ¨æŽ¨ç†æ¨¡åž‹ä¸­å–å¾—äº†å·¨å¤§çš„æˆåŠŸï¼Œå¦‚ OpenAI çš„ Oç³»åˆ—ã€DeepSeek Rç³»åˆ—ï¼ˆDeepSeek-R1ï¼‰ï¼Œä½†è¿™äº›æ¨¡åž‹éƒ½é‡‡ç”¨äº† Rule-Base Reward Modelï¼Œå› æ­¤ Reward Model å…·æœ‰ä¸€å®šçš„å±€é™æ€§ï¼Œåœ¨å¾ˆå¤šåœºæ™¯ä¸å¤Ÿé€šç”¨ï¼Œå› æ­¤æœ¬æ–‡çš„ DeepSeek-GRM æ˜¯æ—¨åœ¨åˆ©ç”¨ SPCT çš„æ–¹å¼æ¥è®­ç»ƒä¸€ä¸ªé€šç”¨åž‹çš„ Reward Modelï¼Œå¹¶ä¸”èƒ½å¤Ÿå¾ˆå¥½å¾— Inference-Time Scaleï¼Œä»¥æ­¤å¾—åˆ°ä¸€ä¸ªåœ¨é€šç”¨ä»»åŠ¡ï¼ˆéžæ•°å­¦ã€ä»£ç ç­‰æœ‰ç²¾ç¡® Rewardï¼‰ä¹Ÿèƒ½æœ‰å¾ˆå¥½æ•ˆæžœçš„æ¨¡åž‹ã€‚

æœ¬æ–‡é¦–å‘äºŽï¼šhttps://bruceyuan.com/post/deepseek-grm-paper-reading-notes.html
2. å‰æ(Preliminaries)
2.1 RM æ¨¡åž‹è®­ç»ƒåˆ†ç±»
deepseek-grm-20250502123401789
deepseek-grm-20250502123401789
è¿™é‡Œçš„åˆ†ç±»éžå¸¸çš„æ¸…æ™°ï¼Œå…ˆåˆ†æˆä¸¤ä¸ªå¤§ç±»ï¼šï¼ˆ1ï¼‰æ‰“åˆ†æ¨¡å¼ï¼ˆScoring Patternsï¼‰ï¼Œæ°›å›´ Pointwise, Pairwiseï¼›ï¼ˆ2ï¼‰ç”Ÿæˆæ‰“åˆ†çš„æ¨¡å¼ï¼šScalarï¼ˆæ ‡é‡æ•°å€¼åž‹ï¼‰ï¼ŒSemi-Scalarï¼ˆåŠæ•°å€¼åž‹ï¼‰ï¼ŒGenerativeï¼ˆç”Ÿæˆå¼ï¼‰ã€‚

å…ˆå¯¹è¾“å…¥è¿›è¡ŒåŒºåˆ†ï¼ˆScoring Patternsï¼‰åŒ…å«ä¸¤ç§ç±»åž‹çš„è¾“å…¥ï¼š

â€¢ ï¼ˆiï¼‰Pointwiseï¼Œè¾“å…¥æ˜¯ä¸€æ¡æ ·æœ¬ï¼ˆæˆ–å¤šä¸ªæ ·æœ¬ï¼‰ï¼Œä½†æ˜¯è¦å¯¹æ¯ä¸€ä¸ªæ ·æœ¬éƒ½è¾“å‡ºå¯¹åº”çš„åˆ†æ•°ã€‚è¿™é‡Œè§£é‡Šä¸€ä¸‹ä¸ºä»€ä¹ˆ pointwise çš„ Scoring Patterns å¯ä»¥æ”¯æŒå¤šç§è¾“å…¥å½¢å¼ï¼ŸåŽŸå› ä¸ºï¼šè®­ç»ƒå®Œä¹‹åŽï¼Œä½ çš„è¾“å…¥å¯ä»¥æ˜¯ä¸€æ¡æ ·æœ¬ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸¤æ¡æ ·æœ¬ï¼Œä¹Ÿå¯ä»¥æ˜¯å¤šæ¡æ ·æœ¬ï¼Œè€Œä¸‹æ–¹çš„ pairwise å½¢å¼çš„ Scoring Pattens è®­ç»ƒå®Œä¹‹åŽï¼Œåªèƒ½ç»™æˆå¯¹çš„æ ·æœ¬è¯„ä¼°ï¼Œå¦‚æžœè¦æ”¯æŒå¤šä¸ªã€å•ä¸ªæ ·æœ¬ï¼Œåˆ™éœ€è¦å…¶ä»–çš„æ“ä½œã€‚
â€¢ ï¼ˆiiï¼‰Pairwiseï¼Œè¾“å…¥è¦æ˜¯æˆå¯¹çš„æ ·æœ¬ï¼Œè¾“å…¥æ˜¯ä¸€ä¸ªå€¼ã€‚å‡è®¾æ˜¯ä¸¤ä¸ªæ ·æœ¬ a, bï¼Œé‚£ä¹ˆè¾“å‡ºæ˜¯ä¸€ä¸ªå€¼ï¼Œå¤§äºŽ0 è¡¨ç¤º a å¥½ï¼Œå°äºŽ0è¡¨ç¤º bå¥½ï¼›æˆ–è€…ç›´æŽ¥è¾“å‡º a / b æ¥è¡¨ç¤º a å¥½è¿˜æ˜¯ b å¥½ã€‚
ç„¶åŽå¯ä»¥å¯¹æ¨¡åž‹çš„è¾“å‡ºæ–¹å¼ï¼ˆReward Generation Paradigmsï¼‰è¿›è¡ŒåŒºåˆ†ï¼Œ

â€¢ ï¼ˆaï¼‰Scalarï¼šè®©æ¨¡åž‹ä¸€ä¸ª Head æ•°å‡ºä¸€ä¸ªæµ®ç‚¹æ•°
â€¢ ï¼ˆbï¼‰Semi-Scalarï¼šå…ˆè®©æ¨¡åž‹ä¸€ä¸ª Head è¾“å‡ºä¸€æ®µåˆ†æžï¼ˆCritiqueï¼‰ï¼Œç„¶åŽå†ç”¨å¦å¤–ä¸€ä¸ª Head è¾“å‡ºä¸€ä¸ªæµ®ç‚¹æ•°ï¼ˆæˆ–è€…ç›´æŽ¥è®¡ç®—æŸ tokençš„ logit å€¼ï¼‰
â€¢ ï¼ˆcï¼‰Generativeï¼šæ¨¡åž‹åªæœ‰ä¸€ä¸ª Headï¼Œè¿™ä¸ª Head æ˜¯é€šè¿‡ç”Ÿæˆçš„æ–¹å¼è¾“å‡º Critique ä»¥åŠæœ€ç»ˆçš„åˆ†æ•°ï¼Œæœ€ç»ˆçš„åˆ†æ•°è¦è‡ªå·±æŠ½å–å‡ºæ¥ã€‚
deepseek-grm-20250502123435456
deepseek-grm-20250502123435456
ç„¶åŽæˆ‘ä»¬å¯ä»¥å¯¹æ­¤è¿›è¡Œç»„åˆï¼š

â€¢ (a) + (i)ã€‚æ²¡æœ‰æ€ç»´é“¾ï¼Œå¤šæ¬¡æŽ¨ç†ç»“æžœéƒ½æ˜¯ä¸€æ ·çš„ï¼Œå› æ­¤æ²¡æ³• Inference-time Scalingã€‚è¿™é‡Œè¯´çš„ Bradley-Terry æŒ‡çš„æ˜¯ï¼š ï¼Œå› æ­¤ Loss å¯ä»¥å®šä¹‰æˆ pairwise lossï¼Œ ï¼ŒN æŒ‡çš„æ˜¯æ•°æ®é›†ä¸­çš„æ ·æœ¬ã€‚
â€¢ (a) + (ii)ï¼Œæ¨¡åž‹è¾“å‡ºçš„æ˜¯ >0 / < 0 æµ®ç‚¹æ•°ï¼Œå› æ­¤ä¹Ÿä¸ Scalingï¼Œè®­ç»ƒ loss æ˜¯ Pointwise Lossã€‚
â€¢ (b) + (i)ï¼Œè¿™é‡Œå› ä¸ºæœ‰ Critique çš„å­˜åœ¨ï¼Œæ¯æ¬¡é‡‡æ ·éƒ½ä¼šæœ‰ä¸åŒçš„ç»“æžœï¼Œæ‰€ä»¥å¯ä»¥ Scalingã€‚
â€¢ (b/c) +ï¼ˆii)ï¼Œå¯ä»¥ Scalingï¼Œä½†æ˜¯è®­ç»ƒå®Œä¹‹åŽåªèƒ½æˆå¯¹è¾“å…¥ã€‚
â€¢ (c) + (i)ï¼Œé€šè¿‡ç”Ÿæˆçš„æ–¹å¼ç”Ÿæˆã€critique å’Œ æ¯ä¸ªæ ·æœ¬çš„ Scoreã€‘ï¼Œç„¶åŽè‡ªè¡Œè§£æžæŠ½å–ç»“æžœã€‚
ä½†æ˜¯ä»Žå®žé™…çš„ç»“æžœç»“æžœæ¥çœ‹ï¼Œ(c) + (i) åœ¨ inference-time scaling çš„æ•ˆæžœè¦å¥½äºŽ (b) + (i)ï¼Œå…·ä½“è§ä¸‹å›¾çš„ç»¿è‰²çº¿ï¼ˆCLoudï¼‰ï¼Œå¤šæ¬¡é‡‡æ ·æå‡ä¸æ˜Žæ˜¾ï¼Œæ‰€ä»¥æœ€ç»ˆé‡‡ç”¨äº† (c) + (i)ï¼Œä¹Ÿå°±æ˜¯ PointWise-GRMã€‚
deepseek-grm-20250502130525536|366
deepseek-grm-20250502130525536|366
2.2 Principleå¯ä»¥æå‡RMæ•ˆæžœ
å‰é¢æåˆ°è¿‡ï¼Œéƒ¨åˆ†é¢†åŸŸå¯ä»¥æœ‰ç²¾ç¡®çš„è§„åˆ™ï¼Œæ¯”å¦‚æ•°å­¦ã€ä»£ç ï¼Œä½†æ˜¯é’ˆå¯¹äºŽä¸€äº›é€šç”¨çš„é¢†åŸŸï¼Œæ¯”å¦‚è§’è‰²æ‰®æ¼”ã€å†™ä½œç­‰ï¼Œè¯„åˆ¤çš„è§„åˆ™å°±ä¼šå˜å¾—æ›´å¤æ‚ã€å¹¶ä¸”é€šå¸¸éƒ½æ²¡æœ‰ä¸€ä¸ªå›ºå®šçš„æ ‡å‡†ç­”æ¡ˆï¼ˆgolden truthï¼‰ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥æŒ‡å®šä¸€äº›å‡†åˆ™ï¼ˆprinciplesï¼‰æ¥è¿›è¡Œæ‰“åˆ†ã€‚

å½“ç„¶è¿™äº›å‡†åˆ™å¯ä»¥æ˜¯æ¨¡åž‹è‡ªå·±ç”Ÿæˆçš„ã€‚ä¸‹é¢è§£é‡Šä¸€ä¸‹è¿™ä¸ªè¡¨æ ¼ï¼Œä»¥ GPT4o-2024-0806ä¸ºä¾‹ï¼ŒGemma-2-27B-it åŒç†ï¼Œä»Žè¡¨æ ¼çš„æ•°æ®å¯ä»¥çœ‹å‡ºï¼š

â€¢ 2 / 3 è¡Œå¯¹æ¯”ï¼Œå¢žåŠ äº†è‡ªæˆ‘å¢žåŠ çš„è¯„ä¼°å‡†åˆ™ï¼ˆprinciplesï¼‰å¯¹äºŽæŒ‡æ ‡æ²¡æœ‰ä»€ä¹ˆæå‡ï¼ˆæ•ˆæžœå·®ä¸å¤šï¼‰ã€‚
â€¢ 2 / 4 è¡Œå¯¹æ¯”ï¼Œé€šè¿‡ä¸€äº›è¿‡æ»¤è§„åˆ™ï¼Œç›¸å¯¹äºŽæ²¡æœ‰è§„åˆ™æœ‰ä¸€å®šçš„æå‡ã€‚3 / 4 è¡Œå¯¹æ¯”ä¹ŸåŒæ ·è¯´æ˜Žå¦‚æ­¤ã€‚
deepseek-grm-20250503212538082|409
deepseek-grm-20250503212538082|409
ä¸Šé¢çš„ç»“æžœå¯ä»¥è®©æˆ‘ä»¬å¾—å‡ºç»“è®ºï¼šç»è¿‡ç­›é€‰çš„è‡ªæˆ‘ç”Ÿæˆçš„è¯„ä¼°å‡†åˆ™å¯ä»¥æå‡ Reward-Model çš„æ•ˆæžœã€‚

3. Self-Principled Critique Tuning(SPCT)
deepseek-grm-20250503213929051
deepseek-grm-20250503213929051
ä»Žè¿™ä¸ªå›¾å¯ä»¥çœ‹å‡ºï¼ŒSPCT ä¸€å…±åŒ…å«ä¸¤ä¸ªå¤§éƒ¨åˆ†éƒ¨åˆ†

â€¢ è®­ç»ƒ
â€¢ RFTï¼ˆrejective fine-tuningï¼‰ä½œä¸ºå†·å¯åŠ¨
â€¢ rule-based online RLï¼ˆreinforcement learningï¼‰ ç”¨äºŽå¼ºåŒ–æ¨¡åž‹ç”Ÿæˆè¯„ä¼°å‡†åˆ™ï¼ˆprincipleï¼‰å’ŒæŽ¨ç†æ‰¹åˆ¤ï¼ˆcritiqueï¼‰çš„èƒ½åŠ›ï¼ŒåŽé¢éƒ½ç”¨ principle å’Œ critique è¡¨ç¤ºã€‚
â€¢ æŽ¨ç†
â€¢ é€šè¿‡ inference-time scaling çš„æ–¹å¼å¢žåŠ  RM çš„æœ€ç»ˆèƒ½åŠ›ã€‚
3.1 è®­ç»ƒ
3.1.1 RFT (Reject fine-tuning)
å‰é¢æåˆ°äº†ï¼Œä¸€ä¸ªé€šç”¨çš„ GRM è¦åšåˆ°è¾“å…¥è‡ªç”±ï¼Œæ‰€ä»¥æˆ‘ä»¬æœ€ç»ˆé‡‡ç”¨çš„æ˜¯ Pointwise-GRMï¼Œç”¨åŒä¸€ä¸ªæ¨¡åž‹ç”Ÿæˆ principle å’Œ critiqueã€‚æ ·æœ¬æž„é€ æ–¹å¼å¦‚ä¸‹ï¼š

â€¢ ç»™å®šä¸€ä¸ª ï¼Œæ˜¯ä¸€å¥è¯ï¼ˆåŒ…å«æ¨¡åž‹çš„ instruction å’Œ outputï¼‰ã€‚æœ‰ä¸ª golden ç»“æžœï¼ˆresponse 1/2 çš„æ‰“åˆ†ï¼‰ï¼Œä»¥åŠè¡¨ç¤º GRM é¢„æµ‹çš„ç»“æžœï¼Œè¿™é‡Œæ ¼å¼æ ·ä¾‹ä¸ºæ¯ä¸€ä¸ªï¼š "principle 1: xxx, principle 2: xxxã€‚Analysis: xxxx, ï¼Œresponse 1 ã€2 FinalScore: [2, 3]"ï¼Œæˆ‘ä»¬å¯ä»¥æŠ½å–å‡º final scoreï¼Œç„¶åŽä¸Žè¿›è¡Œå¯¹æ¯”ã€‚å¯¹äºŽæ¯ä¸€ä¸ªæˆ‘ä»¬éƒ½è¦è¿‡ æ¬¡ GRMï¼ˆå› æ­¤ä¹Ÿå°±ä¼šæœ‰å¤šä¸ªç»“æžœï¼Œä½†æ˜¯æˆ‘ä»¬è¦è¿‡æ»¤æŽ‰ä¸€äº›ç»“æžœï¼Œè¿™ä¸ªè¿‡æ»¤çš„è¿‡ç¨‹å°±æ˜¯æˆ‘ä»¬æ‹’ç»é‡‡æ ·çš„è¿‡ç¨‹ã€‚
â€¢ é¦–å…ˆæˆ‘ä»¬ä¼šæŠŠé¢„æµ‹ç»“æžœå’Œ golden label ä¸ä¸€è‡´çš„è¿‡æ»¤
â€¢ å…¶æ¬¡ä¼šè¿‡æ»¤è¿‡äºŽç®€å•çš„æ ·æœ¬ï¼Œä¹Ÿå°±æ˜¯åœ¨  æ¬¡é‡‡æ ·çš„è¿‡ç¨‹ä¸­ï¼Œéƒ½å’Œ golden label ç»“æžœä¸€æ ·çš„æ ·æœ¬ã€‚
â€¢ å…·ä½“çš„è¿‡æ»¤è¦æ±‚æ˜¯ï¼Œå¯¹äºŽæœ‰å¤šæ¡ response è¾“å…¥çš„æ ·æœ¬ï¼ˆå¦‚ä¸Šé¢æ ·ä¾‹ä¸­çš„ response 1/2 å°±æ˜¯æœ‰ 2 ä¸ª response è¾“å…¥ï¼‰ï¼Œé‚£ä¹ˆæœ€ç»ˆè¦æ±‚äººå·¥æ ‡æ³¨çš„æœ€ä¼˜ response å…·æœ‰æœ€å¤§çš„ scoreï¼›è€Œå¦‚æžœ response åªæœ‰ä¸€æ¡ï¼Œé‚£ä¹ˆè¦æ±‚é¢„æµ‹çš„å¥–åŠ±å€¼ç­‰äºŽ goden labelã€‚( è¡¨ç¤ºå¯¹äºŽç¬¬  æ¡ response çš„ score)
deepseek-grm-20250503220321571
deepseek-grm-20250503220321571
â€¢ ä¸Šé¢çš„çœ‹ä¼¼ç¾Žå¥½ï¼Œä½†æ˜¯æ²¡æœ‰è€ƒè™‘åˆ°ï¼ŒGRM æœ‰é™æ¬¡é‡‡æ ·çš„è¿‡ç¨‹ä¸­ï¼Œå¯èƒ½æ— æ³•ç”Ÿæˆç¬¦åˆ golden labelï¼ˆå…·ä½“æŸä¸€æ¡response å¥½ä»¥åŠæ‰“åˆ†ï¼‰ï¼Œå› æ­¤ä¼šåŠ å…¥ä¸€æ¡äººå·¥æ‰“åˆ†æœ€å¤§çš„ response åˆ° prompt ä¸­ï¼Œè¿™æ¡æ ·æœ¬è¢«å«åš hinted samplingï¼Œå¦‚æžœä½¿ç”¨ hinted sampling åˆ™åªé‡‡æ ·ä¸€æ¬¡ï¼Œå®žéªŒç»“æžœå‘çŽ° hinted sampling çš„æ ·æœ¬ Critique ç»“æžœæ›´çŸ­ï¼ˆè¿™æ ·æ•ˆæžœå¯èƒ½å—é™ï¼‰ï¼Œå› æ­¤åªé€‚åˆåšå†·å¯åŠ¨ï¼Œæ›´å¤šçš„æ•ˆæžœæå‡è¿˜æ˜¯éœ€è¦ online RL
3.1.2 online RL
å¼ºåŒ–å­¦ä¹ éƒ¨åˆ†å› ä¸ºä½¿ç”¨ rule-based rewardï¼Œå› æ­¤ç»†èŠ‚åè€Œç›¸å¯¹æ¯”è¾ƒç®€å•ã€‚å…·ä½“æ˜¯ä½¿ç”¨ GRPO ç®—æ³•åšè®­ç»ƒï¼Œè¾“å…¥æ˜¯ï¼šä¸€ä¸ª  (instruction) ä»¥åŠ  ï¼ˆn æ¡ responseï¼‰ï¼Œè¾“å‡ºæ˜¯ï¼šGRM ç”Ÿæˆçš„ principle å’Œ critiqueï¼Œç„¶åŽæŠ½å‡ºåŽ»å¯¹åº”çš„åˆ†æ•°ï¼Œè®¡ä¸º ï¼Œä¸‹é¢çš„å…¬å¼æ€»ç»“èµ·æ¥å°±ä¸€å¥è¯ï¼šé¢„æµ‹å¯¹äº†ç»™ 1 åˆ†ï¼Œé¢„æµ‹é”™äº†ç»™ -1 åˆ†ï¼Œæ²¡æœ‰å…¶ä»–çš„æ ¼å¼åˆ†ã€‚
deepseek-grm-20250503222004215
deepseek-grm-20250503222004215
å…¶ä»–ç»†èŠ‚ï¼šKL æ•£åº¦çº¦æŸçš„ç³»æ•°æ¯” DeepSeek-R1 æ›´å¤§ï¼Œç„¶åŽè®¾ç½® GRPO ä¸­ rollout æ¬¡æ•°ä¸º 4 æ¥å¹³è¡¡æ•ˆçŽ‡å’Œæ•ˆæžœã€‚

3.2 æŽ¨ç†
SPCT æœ€é‡è¦çš„åˆè¡·æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯ã€inference-time scalingã€‘ã€‚å› æ­¤æŽ¨ç†çš„æ—¶å€™æœ‰ä¸¤ä¸ªæ–¹å¼æ¥ Scaling è¾¾åˆ°æå‡æ•ˆæžœçš„ç›®çš„ã€‚

â€¢ Voting with Generated Rewardsã€‚å…·ä½“è§£é‡Šä¸ºï¼šæŽ¨ç†çš„æ—¶å€™ sample å¤šæ¡ç»“æžœï¼Œé‚£ä¹ˆå°±ä¼šæœ‰å¤šä¸ªç»“æžœçš„ scoreï¼ŒæŠŠæ¯ä¸ª response çš„ç»“æžœåŠ èµ·æ¥ä½œä¸ºæœ€ç»ˆçš„ç»“æžœã€‚
â€¢ Meta Reward Model Guided Votingã€‚ä¹Ÿå°±æ˜¯è¯´ä¸æ˜¯å¯¹å¤šæ¬¡é‡‡æ ·çš„ Score ç›´æŽ¥åŠ èµ·æ¥ï¼Œå› ä¸ºæœ‰æ—¶å€™ GRM å¯èƒ½ç”Ÿæˆä¸€äº›è´¨é‡ä½Žçš„ principle å’Œ critiqueï¼Œè€Œæ˜¯é€šè¿‡è®­ç»ƒä¸€ä¸ª meta rewrd model æ¥å¼•å¯¼æŠ•ç¥¨è¿‡ç¨‹ã€‚å…·ä½“å°±æ˜¯è®­ç»ƒä¸€ä¸ªäºŒåˆ†ç±»ï¼Œè¡¨ç¤ºå½“å‰çš„ principle å’Œ critique æ˜¯å¦è¦è¢«ç”¨äºŽæŠ•ç¥¨ï¼Œä¹Ÿå°±æ˜¯è¿‡æ»¤æŽ‰ä¸€äº›ä½Žè´¨é‡çš„é‡‡æ ·ç»“æžœã€‚æ¯”å¦‚ Figure 3 ä¸­çš„ meta RM å°±è¿‡æ»¤æŽ‰äº† 2 4 ä¸¤ä¸ªç»“æžœï¼Œåªç”¨ 1 3 ç”¨äºŽæŠ•ç¥¨ã€‚ä¸€èˆ¬è®¾ç½®ä¿ç•™ä¸€åŠçš„é‡‡æ ·ç»“æžœã€‚
4. å®žéªŒç»“æžœ
4.1 ä¸»å®žéªŒåˆ†æž
â€¢ 27Bçš„ spct-GRMæ¨¡åž‹æ¯” 340B å¤§æ¨¡åž‹æ•ˆæžœè¿˜è¦å¥½ï¼Œå¹¶ä¸”ä¸åƒ scalar å’Œ semi-scalar çš„æ¨¡åž‹ä¸€æ ·æ¯”è¾ƒå¤§çš„ biasï¼ˆæ¯”å¦‚ ppe ä»»åŠ¡ï¼Œå¯éªŒè¯å¥–åŠ±ä»»åŠ¡å°±è¡¨çŽ°æ›´å¥½ï¼‰ã€‚
â€¢ ç›¸å¯¹äºŽ LLM-as-a-Judge çš„æ–¹å¼ï¼Œå¸¦æœ‰ spct çš„GRM å› ä¸ºæœ‰ principle çš„ç”Ÿæˆï¼ŒGRMç›¸å¯¹æ›´å¥½ä¸€äº›ã€‚
â€¢ æ•´ä½“ä¸Šè¯´å°±æ˜¯ï¼šSPCT æå‡äº† GRM åœ¨é€šç”¨ä»»åŠ¡çš„è¯„ä¼°èƒ½åŠ›ï¼Œå¹¶ä¸”å…·æœ‰æ›´å°‘çš„é¢†åŸŸåå·®ï¼ˆä¸ä¸€å®šéžå¾—æ˜¯å¯éªŒè¯å¥–åŠ±çš„é¢†åŸŸæ‰è¡¨çŽ°å¥½ï¼‰ã€‚
deepseek-grm-20250503223555628
deepseek-grm-20250503223555628
4.2 Inference Scaling
Inference-time Scalingï¼ŒVoting ä»Ž 1 -> 32ï¼Œæ•ˆæžœé€æ­¥æå‡ï¼Œå¹¶ä¸” MetaRM ä¼šè¿›ä¸€æ­¥å¸¦æ¥æ•ˆæžœï¼Œè¿™ä¸ªæ— éœ€å¤šè¯´ã€‚

deepseek-grm-20250503224457640|445
deepseek-grm-20250503224457640|445
deepseek-grm-20250503225713996
deepseek-grm-20250503225713996
4.3 æ¶ˆèžå®žéªŒ
â€¢ å„ä¸ªç»„ä»¶æ•ˆå‡æœ‰æ•ˆæžœæå‡ï¼Œå…¶å®žæ¯”è¾ƒé‡è¦çš„æ˜¯ Princeple Generation ä»¥åŠ General Instruction Dataï¼ˆè¿™å‘Šè¯‰æˆ‘ä»¬æ··åˆé€šç”¨æ•°æ®çš„é‡è¦æ€§ï¼‰ã€‚
â€¢ non-hinted sampling æ›´é‡è¦ï¼Œæ¯”è¾ƒåˆç†ï¼Œç»™äº†æ¨¡åž‹æ›´å¤šçš„æŽ¢ç´¢å’Œé‡‡æ ·ç©ºé—´ã€‚hinted sampling æ›´å¤šæ˜¯ä¸ºäº†é˜²æ­¢æ¨¡åž‹è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¸åˆ°ä¸œè¥¿ï¼Œæ˜¯ä¿ä¸‹çº¿çš„ä¸œè¥¿ã€‚
â€¢ æœ€ç»ˆé‡è¦çš„ï¼ŒRL æ¯” RFT æ›´é‡è¦ï¼Œ RL is all we needï¼ˆðŸ¤£66.1 -> 68.7ï¼‰ã€‚
deepseek-grm-20250503224750765|575
deepseek-grm-20250503224750765|575
 

